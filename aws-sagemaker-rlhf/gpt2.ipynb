{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/Documents/untapped/ml-flow/venv/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:248: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 0. imports\n",
    "# pip install bitsandbytes\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig\n",
    "\n",
    "\n",
    "# Load a pretrained model\n",
    "MODEL_PATH = \"distilgpt2\"\n",
    "# Tokenizer + Model + Data Collator\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "lora_config = LoraConfig(\n",
    "        r=4,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(MODEL_PATH, quantization_config=bnb_config, peft_config=lora_config, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "data_collator = DataCollatorForCompletionOnlyLM(tokenizer=tokenizer, mlm=False)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'prompt', '__index_level_0__'],\n",
       "        num_rows: 763\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'prompt', '__index_level_0__'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "from src.instruction_pipeline import (\n",
    "    INSTRUCTION_KEY,\n",
    "    RESPONSE_KEY,\n",
    "    END_KEY,\n",
    "    INTRO_BLURB,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"data/prompts_merged.csv\", index_col=0)\n",
    "\n",
    "def combine_text(instruction):\n",
    "    text = f\"\"\"{INTRO_BLURB}\n",
    "\n",
    "{INSTRUCTION_KEY}\n",
    "{instruction}\n",
    "\n",
    "{RESPONSE_KEY}\n",
    "\"\"\"\n",
    "    return text\n",
    "\n",
    "df['text'] = [combine_text(*row) for row in df[['prompt']].values]\n",
    "df = df[['text', 'prompt']]\n",
    "dataset = dict()\n",
    "dataset['train'] = Dataset.from_pandas(df[:-30])\n",
    "dataset['validation'] = Dataset.from_pandas(df[-30:])\n",
    "dataset_dict = DatasetDict(dataset)\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWrite a story about a character who faces rejection and learns the importance of self-love and self-acceptance.\\n\\n### Response:\\n',\n",
       " 'prompt': 'Write a story about a character who faces rejection and learns the importance of self-love and self-acceptance.',\n",
       " '__index_level_0__': 239}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 763/763 [00:00<00:00, 2955.24 examples/s]\n",
      "Map: 100%|██████████| 30/30 [00:00<00:00, 2808.31 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 763/763 [00:00<00:00, 156921.35 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 30/30 [00:00<00:00, 6605.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 256\n",
    "\n",
    "def tokenize_function(example):\n",
    "    example['input_ids'] = tokenizer.encode(example['text'], truncation=True, padding=\"max_length\", max_length=SEQ_LEN)\n",
    "    return example\n",
    "\n",
    "def prepare_data(dataset):\n",
    "    dataset = dataset.map(tokenize_function, remove_columns=['text'])\n",
    "\n",
    "    dataset.set_format('pt')\n",
    "\n",
    "    return dataset\n",
    "\n",
    "data = prepare_data(dataset_dict)\n",
    "data.save_to_disk(\"./output/dataset_gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "ppo_config = PPOConfig(learning_rate=1.5e-5, ppo_epochs=1, batch_size=4)\n",
    "ppo_trainer = PPOTrainer(config=ppo_config, model=model, tokenizer=tokenizer, dataset=data['train'])\n",
    "# reward kwargs for reward model\n",
    "reward_kwargs = {'return_all_scores': True, 'function_to_apply': 'none', 'batch_size': 16}\n",
    "# generation kwargs for gpt2/dolly\n",
    "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id, 'max_new_tokens': SEQ_LEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ppo_trainer.accelerator.device\n",
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\n",
    "\n",
    "reward_name = \"OpenAssistant/reward-model-deberta-v3-large-v2\"\n",
    "reward_model, reward_tokenizer = AutoModelForSequenceClassification.from_pretrained(reward_name, device_map=device), AutoTokenizer.from_pretrained(reward_name, torch_device=device)\n",
    "def pipeline(batch): # later switch to batch encoding and batch inference\n",
    "    inputs = tokenizer.batch_encode_plus(batch, return_tensors='pt', truncation=True, padding=\"max_length\", max_length=SEQ_LEN).to('cuda')\n",
    "    scores = reward_model(**inputs)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    print(len(batch))\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    #### Get response from gpt2\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        response = ppo_trainer.generate(query, **gen_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-SEQ_LEN:])\n",
    "    batch[\"completion\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors] # batch[\"completion\"] = tokenizer.batch_decode(response), look at ppo.py\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [(p, c) for p, c in zip(batch[\"prompt\"], batch[\"completion\"])]\n",
    "    pipe_outputs = pipeline(texts, **reward_kwargs)\n",
    "    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n",
    "\n",
    "    #### Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "    # Try this code in a Sagemaker notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
